{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nissan Warranty Judge — Rule-based Model\n",
    "# Version: 1.0 as of 2025-12-11.  \n",
    "# Author: Gabriel Alves (PS/QMC 11-JP)\n",
    "# Status: Production, replaces old working_dev notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 0. IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill\n",
    "from rapidfuzz import fuzz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 1. CONFIGURATION\n",
    "# ============================================================\n",
    "\n",
    "# Monthly claim date (format: yyyy/mm/dd)\n",
    "CLAIM_DATE = \"2025/11/01\"\n",
    "\n",
    "# Sheet name containing monthly Nissan PS data\n",
    "SHEET_PS = \"For_sap_C\"\n",
    "\n",
    "\n",
    "# Datetime version of claim date (used across pipeline)\n",
    "claim_date_ts = pd.to_datetime(CLAIM_DATE)\n",
    "\n",
    "# ============================================================\n",
    "# PART FILTER LISTS (Behavior-preserving)\n",
    "# These lists define subparts that should be auto-accepted or \n",
    "# filtered in objection logic. Business rules unchanged.\n",
    "# ============================================================\n",
    "\n",
    "PART_GROUPS = {\n",
    "    \"GLOW_PLUG\": [\n",
    "        '101023XN4A', '140355X00A', '140365X00A', '144113XN3E', '144155X00A',\n",
    "        '144455X00A', 'NIMEXU03Q1', '120', 'BUHIN0029100', '147306RC0A',\n",
    "        'ATM01F0009', '320106US1A', '290Y63NF0B', '144116UA0A', '552226RN1A',\n",
    "        '56280JP00A', '144986UA2A', '144616RC0B', '658406UA0A', '1518940P00',\n",
    "        '668926UA0A', 'KE90299975', '2144088M00', '147496RC1A', '200A06RA2C',\n",
    "        '166356RC0A', '147356RC0B', '166186RC0B', '166126RC0A', 'B08A26RX0A',\n",
    "        '166186RC0D', 'KE90090033', '450', '12309EN20A', '442', 'KE90999945',\n",
    "        '150666RC0A', '140944KV0A', '130496RC0A', '331144BA0B', '0142200Q0C',\n",
    "        '37120JD01A', '37120JD00B', '331424BA0C', '164397S02A', '371717S00A',\n",
    "        '924776RA1A', '250853JA0A', '110261CA0A', '383423WX0C', '1643956S1A',\n",
    "        '12315ED010', '92473N823A', '24009F991J', '147106RC0B', '223416UL0A',\n",
    "        '391006RC4D', '201006RU2C', '223206UA0A', 'KE90200075', 'KE90090041',\n",
    "        '14094JG30A', '14064JG30A', 'KE90090043', '112986RN0D', '14064JG30B',\n",
    "        '166356RC0B', '166186RC0C', 'BUHIN0024000', '224486RC0C', '2277000Q0D',\n",
    "        '201006RU1C', '01125E6071', '144606RC2A', '140416RC1A', '140355CA0A',\n",
    "        '166351LA0B', '140325CA0A', '166005CA0A', '226935CA0A', '224015CA1D',\n",
    "        '161755CA0A', '3100921X00', '144115CA3D', '144645CA1A', '37121JK20B',\n",
    "        '0122500062', '151925CA1A', '144645CB0A', '151895CA0B', '144155CA0A',\n",
    "        '144505CA1A', '130495CA0A', '12315D0201', '402622Y00A', '144115CA3C',\n",
    "        '151925CA1B', '213045CB1A', '37120AH00A', '144455CB0A', '37171AL60A',\n",
    "        '144506GP0A', '383430P013', '37120AL60A', '140949BA0A', '151895CA0A',\n",
    "        '101026HN3A', '210144HK0A', '20692JK00B', '999MPCV0NS3', '1233016A0A',\n",
    "        '210495CA0B', '210495CA0A', '130505CA0A', '110625CA2A', '110625CA1A',\n",
    "        '089183401A', '166183VA0A', '22636N4200', '11026AD200', '151965CB0A',\n",
    "        '15196MB40B', '135335CA0A', 'B08026HL0B', '226A05CA0A', 'B08026HL0A',\n",
    "        '243617990A', '2060241G00', '210141KC0A', '13050EN20B', '22131EN205',\n",
    "        '206921HA0A', '140361VA0A', '101026MAHA', '21430AX30A', '166001VA0C',\n",
    "        'A44015CA0A', '54588JK00A', '111405CA0B', '170404HK0A', '37120CG10A',\n",
    "        '166121LA1A', '383430P001', '999BK00W20SS', '175206GP0A', '208B25CA0A',\n",
    "        '2162632U00', '101026HN4A', '144505CA1C', '215147990B', '175225CA0A',\n",
    "        '175215CA0A', '166385CA0A', '151975CA1A', '144995CA0B', '144995CA0A',\n",
    "        '144985CA0B', '144985CA0A', 'CP1H', '16175MA70A', '16683MA70A',\n",
    "        '14722EC00A', '16684MA70A', '16700MA70D', '14722AD200', '16680MA70A',\n",
    "        '14719EC00A', 'NLLCWS0021', '1471943G02', '16682MA70A', '14035MA70A',\n",
    "        '16681MA70A'\n",
    "    ],\n",
    "\n",
    "    \"HIGH_PRESSURE_PUMP\": [\n",
    "        '17520HY00A', '11026JA00A', '166181KC0A', '1520865F0E', '140351KC0B',\n",
    "        '16630HY00A', '140E26MR0A', '132311KC6E', '626606MR0A', '480014BA0C',\n",
    "        '233004BB0B', '31935X420D', '3191829X0C', '165006MA2B', '165766MA1B',\n",
    "        '149306FM0A', '21503DF40A', '140014BT0A', '999MPNS300P', '241106MA0A',\n",
    "        '65616MA0A', '66830DF30A', '161194BB2A', '391014BB8E', '260606MR0A',\n",
    "        '663184CC0A', '226805RB0A', 'D60104BA5A', '226931PM0A', '319351XF0C',\n",
    "        '240236MR1B', '112204BB0A', '112544BB1A', '349356MA0A', '240126MR1C',\n",
    "        '658406MR0A', '165546MA2B', '623106MR5A', '999M147C650', '240834MS1A',\n",
    "        '166303JY0A', '499', '401', '166186RC0A', '166306RC0A', '170406MA0A',\n",
    "        '173429TA0A', '565', '173436FK0A', '166384BB0A', '166331KC0A', '144656RC0B',\n",
    "        '140356RC0A', '2148189900', '161756RC0A', '175206RC0B', '166306RC1A',\n",
    "        '118106RC0A', '118126N200', '999MPL25500P', '1520865F1B', '999BK00W20Q',\n",
    "        '210495NA3A'\n",
    "    ],\n",
    "\n",
    "    \"IGNITION_COIL\": ['224481HC0A'],\n",
    "\n",
    "    \"CONTROL_UNIT\": [\n",
    "        '23703HG00F', '237037JA1A', '170406HA0A', '17342CE800'\n",
    "    ],\n",
    "\n",
    "    \"SENSOR_ASSEMBLY\": ['250606FK0A', '250606FK5A'],\n",
    "\n",
    "    \"FUEL_PUMP_MOUNTING_UNIT\": [\n",
    "        '170406FK0A', '170407FV1A', '173423VA0A', '173433VA0A', '252307990A',\n",
    "        '166351LA0A', 'K88206GG0A', 'LSU4.2', '22693CD700'\n",
    "    ],\n",
    "\n",
    "    \"RADIAL_PISTON_PUMP\": ['A6600MA70B'],\n",
    "\n",
    "    \"INJECTION_VALVE\": [\n",
    "        '144156RC0B', '402624GA0D', '101026RCAA', '210496RC2A', '144456RC0A',\n",
    "        '144646RC0A', '206928H30A', '206925NA0A', '147226RC0B', '147226CA0A',\n",
    "        '147196RC0A', '1518969F00', '150661KC0A', '151936RC0A', '150666RC0B',\n",
    "        '291A96XK0A', 'XBGA16XK0B', '290Y63NA1A', '101026UAAE', '166006RC1A',\n",
    "        'A44016RC0B', '290T56UM0A', '110264N200', '224016RC1E', '140016RC0A',\n",
    "        '119A06UA0A', '150661HS0C', 'KE90090144', '295G36LS0A', '295B06UM9A',\n",
    "        'KE90899933', 'KE90200045', '402624GA0C', '200A06UM0C', 'B08A26UM2A',\n",
    "        '152089F60A', 'KE90100035', 'KE90090133', '132706RC2A', '22131EN215',\n",
    "        '210496RC0A', '213045CB0A', '213045CB0B', '01225A0111', 'KE90090143',\n",
    "        '131', '237036UA0A', '999BK00W20N0', '166006RC0A', '01223A2031',\n",
    "        '01225A2011', '54588EN00A', 'B08A26UM0A', '39752ET02B', '383428E000',\n",
    "        '92472N823A', '92474N823A', '14069JD00A', 'KE90090134', 'KE90399932',\n",
    "        '101036UAAE', '110561KC0B', '1320700Q0A', '132075NA0C', '161756UM0A',\n",
    "        '144656UM0A', '110446RC0A', '132706RC0B', '132706RC0A', '150662Y510',\n",
    "        '135104BA0A', '150256RC0A', '166386RC1A', '175216RC0B', '140701LA0A',\n",
    "        '11026EA20A', '150539HS0A', '121396RC0A', '01223A0121', '150661CA0A',\n",
    "        '101', '123106UA0B', '12315EE000', '151926RC0A', '210106UA0A',\n",
    "        '11022AD200', '30223ET00A', '391006UM2D', 'KE90299935', '01125A1051',\n",
    "        '290Y66UM0A', '223406UL0A', '210496RC1A', '226A06UA0B', '226406UA0C',\n",
    "        '164324KV0A', '2422889974', '1102601M02', '0155800411', '20825HV70A',\n",
    "        '1643900Q1C', 'KE90090174', 'KE90299945', '166185CA0A', '166006TA0A',\n",
    "        '140', '201', '199', '0122300Q0A', '40178JA000', '166386RC0A',\n",
    "        '151976RC0A', '144116UA1A', '181', '1520865F0A', '295B06RA9A',\n",
    "        '878446RR5B', '550446RA0B', 'AYBGDL2000JP', '92471N823A', '226936UA0A',\n",
    "        '402626RA0A', '200A06RU0A', '400730L700', '226456RC1A', 'NLLCWS0024',\n",
    "        'AY14140718', '166006MR0B', '132316RC5E', '150664W000'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Optional: quick access variables (behavior unchanged)\n",
    "GLOW_PLUG = PART_GROUPS[\"GLOW_PLUG\"]\n",
    "HIGH_PRESSURE_PUMP = PART_GROUPS[\"HIGH_PRESSURE_PUMP\"]\n",
    "IGNITION_COIL = PART_GROUPS[\"IGNITION_COIL\"]\n",
    "CONTROL_UNIT = PART_GROUPS[\"CONTROL_UNIT\"]\n",
    "SENSOR_ASSEMBLY = PART_GROUPS[\"SENSOR_ASSEMBLY\"]\n",
    "FUEL_PUMP_MOUNTING_UNIT = PART_GROUPS[\"FUEL_PUMP_MOUNTING_UNIT\"]\n",
    "RADIAL_PISTON_PUMP = PART_GROUPS[\"RADIAL_PISTON_PUMP\"]\n",
    "INJECTION_VALVE = PART_GROUPS[\"INJECTION_VALVE\"]\n",
    "\n",
    "# ============================================================\n",
    "# DERIVED CONSTANTS\n",
    "# ============================================================\n",
    "\n",
    "# Parts where color-based logic should be ignored\n",
    "CODES_IGNORE_COLOR = set(\n",
    "    GLOW_PLUG\n",
    "    + HIGH_PRESSURE_PUMP\n",
    "    + IGNITION_COIL\n",
    "    + CONTROL_UNIT\n",
    "    + SENSOR_ASSEMBLY\n",
    "    + FUEL_PUMP_MOUNTING_UNIT\n",
    "    + INJECTION_VALVE\n",
    ")\n",
    "\n",
    "# Automatic sorting depending on the beginning of part number\n",
    "PART_GROUP_PATTERNS = {\n",
    "    \"A6600\": \"INJECTOR\",\n",
    "    \"13276\": \"INJECTOR\",\n",
    "    \"13270\": \"INJECTOR\",\n",
    "    \"14710\": \"INJECTOR\",\n",
    "    \"16672\": \"INJECTOR\",\n",
    "    \"14035\": \"Injection Valve\",\n",
    "    \"21049\": \"Injection Valve\",\n",
    "    \"16600\": \"Injection Valve\",\n",
    "    \"14465\": \"Injection Valve\",\n",
    "    \"16175\": \"Injection Valve\",\n",
    "    \"16630\": \"High Pressure Pump\",\n",
    "    \"17520\": \"High Pressure Pump\",\n",
    "    \"16072\": \"Dosing module\",\n",
    "    \"208S4\": \"Dosing module\",\n",
    "    \"17040\": \"Fuel Pump Mounting Unit\",\n",
    "    \"17342\": \"Fuel Pump Mounting Unit\",\n",
    "    \"17343\": \"Fuel Pump Mounting Unit\",\n",
    "    \"11065\": \"GLOW PLUG\",\n",
    "    \"24009\": \"GLOW PLUG\",\n",
    "    \"11067\": \"GLOW PLUG\",\n",
    "    \"22790\": \"NOx sensor\",\n",
    "    \"16618\": \"O-Ring\",\n",
    "    \"16635\": \"O-Ring\",\n",
    "    \"17521\": \"Supporting Disc\",\n",
    "    \"17520\": \"Supporting Disc\",\n",
    "    \"16612\": \"Supporting Disc\",\n",
    "    \"25060\": \"Sensor Assembly\",\n",
    "    \"23703\": \"CONTROL UNIT\",\n",
    "    \"14722\": \"RAIL\",\n",
    "    \"14735\": \"RAIL\",\n",
    "    \"B08D0\": \"RAIL\",\n",
    "    \"16683\": \"RAIL\",\n",
    "}\n",
    "\n",
    "# Normalize free-text expected group names to standard form\n",
    "EXPECTED_GROUP_NORMALIZATION = {\n",
    "    \"fuel pump assy\": \"fuel pump assembly\",\n",
    "    \"fuel pump mount unit\": \"fuel pump mounting unit\",\n",
    "    \"sensor assy\": \"sensor assembly\",\n",
    "    \"o2 sensor\": \"oxygen sensor\",\n",
    "    \"abs hydraulic\": \"hydraulic unit / abs\",\n",
    "    \"control unit\": \"control unit\",\n",
    "    \"controle unit\": \"control unit\",\n",
    "    \"camshaft sensor\": \"camshaft position sensor\",\n",
    "    \"brake master cyl\": \"brake master cylinder\",\n",
    "    \"wheel speed\": \"wheel speed sensor\",\n",
    "}\n",
    "\n",
    "# Reference No. month-letter → month-code mapping\n",
    "MONTH_LETTER_TO_CODE = {\n",
    "    \"L\": \"Jan\",  # 1\n",
    "    \"A\": \"Feb\",  # 2\n",
    "    \"B\": \"Mar\",\n",
    "    \"C\": \"Apr\",\n",
    "    \"D\": \"May\",\n",
    "    \"E\": \"Jun\",\n",
    "    \"F\": \"Jul\",\n",
    "    \"G\": \"Aug\",\n",
    "    \"H\": \"Sep\",\n",
    "    \"I\": \"Oct\",\n",
    "    \"J\": \"Nov\",\n",
    "    \"K\": \"Dec\",\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def align_to_template(\n",
    "    df: pd.DataFrame,\n",
    "    template_path: str,\n",
    "    column_mapping: dict | None = None,\n",
    "    default_value=np.nan,\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Ensure df has at least all columns from template_path.\n",
    "    - If template col exists in df: keep as is.\n",
    "    - Else if mapping is provided and mapped source col exists in df: copy.\n",
    "    - Else: create col with default_value.\n",
    "    Returns df with columns ordered like the template.\n",
    "    \"\"\"\n",
    "    template_header = pd.read_excel(template_path, nrows=0)\n",
    "    template_cols = list(template_header.columns)\n",
    "\n",
    "    column_mapping = column_mapping or {}\n",
    "\n",
    "    for col in template_cols:\n",
    "        if col in df.columns:\n",
    "            continue\n",
    "\n",
    "        # If we have an explicit mapping, use it\n",
    "        src = column_mapping.get(col)\n",
    "        if src and src in df.columns:\n",
    "            df[col] = df[src]\n",
    "        else:\n",
    "            df[col] = default_value\n",
    "\n",
    "    # Reorder columns to match template first; keep extra cols at the end\n",
    "    ordered_existing = [c for c in template_cols if c in df.columns]\n",
    "    extra_cols = [c for c in df.columns if c not in ordered_existing]\n",
    "    return df[ordered_existing + extra_cols]\n",
    "\n",
    "\n",
    "def normalize_bosch_part_no(pn):\n",
    "    \"\"\"\n",
    "    Normalize Bosch part numbers:\n",
    "    - Convert to string\n",
    "    - Strip spaces\n",
    "    - Remove trailing '.0' from Excel float artifacts.\n",
    "    \"\"\"\n",
    "    if pd.isna(pn):\n",
    "        return None\n",
    "    s = str(pn).strip()\n",
    "    if s.endswith(\".0\"):\n",
    "        s = s[:-2]\n",
    "    return s.replace(\" \", \"\")\n",
    "\n",
    "\n",
    "def translate(df_main: pd.DataFrame,\n",
    "              df_translation: pd.DataFrame,\n",
    "              column1: str,\n",
    "              column2: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Rename columns in df_main based on a translation table.\n",
    "\n",
    "    df_translation[column1] = current column names\n",
    "    df_translation[column2] = new column names\n",
    "    \"\"\"\n",
    "    current_columns = list(df_translation[column1])\n",
    "    new_columns = list(df_translation[column2])\n",
    "\n",
    "    df_main.rename(columns=dict(zip(current_columns, new_columns)), inplace=True)\n",
    "    return df_main\n",
    "\n",
    "\n",
    "def normalize_nissan_bosch_pn(pn):\n",
    "    \"\"\"\n",
    "    Normalize Nissan/Bosch part numbers:\n",
    "    - Remove spaces, hyphens, dots and non-alphanumerics\n",
    "    - Keep only leading 8–12 chars (drop suffixes like KB, T00, etc.).\n",
    "    \"\"\"\n",
    "    if pd.isna(pn):\n",
    "        return None\n",
    "\n",
    "    s = str(pn).replace(\" \", \"\").replace(\"-\", \"\").replace(\".\", \"\")\n",
    "    s = re.sub(r\"[^0-9A-Za-z]\", \"\", s)\n",
    "\n",
    "    match = re.match(r\"([0-9A-Za-z]{8,12})\", s)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_most_common_ezkl(df: pd.DataFrame, parts_no_prefix: str):\n",
    "    \"\"\"\n",
    "    From EZKL mapping table, get the most common EZKL Name for a given prefix.\n",
    "    \"\"\"\n",
    "    matching_rows = df[df[\"Bosch Parts No. Prefix\"] == parts_no_prefix]\n",
    "    if not matching_rows.empty:\n",
    "        return matching_rows[\"EZKL Name\"].mode()[0]\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_letter_from_claim_date(claim_date: str) -> str:\n",
    "    \"\"\"\n",
    "    Map claim date (string) to Nissan claim letter based on month.\n",
    "    \"\"\"\n",
    "    month_to_letter = {\n",
    "        1: \"L\", 2: \"A\", 3: \"B\", 4: \"C\", 5: \"D\", 6: \"E\",\n",
    "        7: \"F\", 8: \"G\", 9: \"H\", 10: \"I\", 11: \"J\", 12: \"K\"\n",
    "    }\n",
    "\n",
    "    claim_date = pd.to_datetime(claim_date, errors=\"coerce\")\n",
    "    return month_to_letter[claim_date.month]\n",
    "\n",
    "\n",
    "def get_OEM_date_month(objection_id: str) -> int:\n",
    "    \"\"\"\n",
    "    Decode OEM month from the 3rd character of the objection_id.\n",
    "    A = 1, B = 2, ..., Z = 26\n",
    "    \"\"\"\n",
    "    alphabet_dict = {letter: index for index, letter in enumerate(string.ascii_uppercase, start=1)}\n",
    "    third_character = objection_id[2].upper()\n",
    "    return alphabet_dict.get(third_character, None)\n",
    "\n",
    "\n",
    "def convert_to_date(value):\n",
    "    \"\"\"\n",
    "    Convert various date encodings to pandas.Timestamp:\n",
    "    - Excel serial numbers (int/float or numeric string)\n",
    "    - 'yyyy/mm' strings\n",
    "    - otherwise return NaT\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Excel serial number (int, float, or numeric string)\n",
    "        if isinstance(value, (int, float)) or (isinstance(value, str) and value.isdigit()):\n",
    "            base_date = datetime(1899, 12, 30)  # Excel's epoch\n",
    "            days = int(value)\n",
    "            return base_date + timedelta(days=days)\n",
    "\n",
    "        # yyyy/mm formatted string\n",
    "        if isinstance(value, str):\n",
    "            return pd.to_datetime(value, format=\"%Y/%m\", errors=\"coerce\")\n",
    "\n",
    "        return pd.NaT\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "\n",
    "def clean_vehicle_mfd(val):\n",
    "    \"\"\"\n",
    "    Normalize Vehicle MFD:\n",
    "    - NaN → NaT\n",
    "    - 4-digit year (int/float/str) → yyyy-01-01\n",
    "    - 'yyyy/mm' → first of that month\n",
    "    - other strings → parsed by pandas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if pd.isna(val):\n",
    "            return pd.NaT\n",
    "\n",
    "        # numeric year like 2018 or 2018.0\n",
    "        if isinstance(val, (int, float)):\n",
    "            return pd.to_datetime(f\"{int(val)}-01-01\")\n",
    "\n",
    "        val_str = str(val).strip()\n",
    "\n",
    "        # 4-digit year\n",
    "        if re.match(r\"^\\d{4}$\", val_str):\n",
    "            return pd.to_datetime(f\"{val_str}-01-01\")\n",
    "\n",
    "        # 'yyyy/mm'\n",
    "        if re.match(r\"^\\d{4}/\\d{1,2}$\", val_str):\n",
    "            return pd.to_datetime(val_str, format=\"%Y/%m\", errors=\"coerce\")\n",
    "\n",
    "        # fallback\n",
    "        return pd.to_datetime(val_str, errors=\"coerce\")\n",
    "\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# BUSINESS RULE FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "def check_burden_ratio(row: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Check burden ratio correctness based on EZKL, MFD, contract dates, and special HDEV5 logic.\n",
    "    Returns:\n",
    "        0 if correct\n",
    "        1 if incorrect\n",
    "    Note: this function assumes row has columns:\n",
    "          'Vehicle MFD', 'EZKL Name', 'Customer Parts No.', 'Burden Ratio',\n",
    "          'Standard Burden Ratio', 'Current Burden Ratio',\n",
    "          'New BR Date', 'SAP Date', '類別区分'\n",
    "    \"\"\"\n",
    "    # Ensure \"Vehicle MFD\" is converted to a datetime object (yyyy/mm)\n",
    "    mfd = pd.to_datetime(row[\"Vehicle MFD\"], format=\"%Y/%m\")\n",
    "\n",
    "    if row[\"EZKL Name\"] == \"HDEV5\":\n",
    "        # Special cases based on Customer Parts No. and 類別区分\n",
    "        if (\n",
    "            \"166001VA0A\" in row[\"Customer Parts No.\"]\n",
    "            or \"166001VA0B\" in row[\"Customer Parts No.\"]\n",
    "            or \"166001VA0C\" in row[\"Customer Parts No.\"]\n",
    "        ):\n",
    "            if re.match(r\"^H\", row[\"類別区分\"]):\n",
    "                # Vehicle MFD date ranges for H-type\n",
    "                if mfd <= datetime(2021, 6, 30):\n",
    "                    return 0 if 2.4 <= row[\"Burden Ratio\"] <= 3.4 else 1\n",
    "                elif mfd >= datetime(2021, 7, 1):\n",
    "                    return 0 if 49.5 <= row[\"Burden Ratio\"] <= 50.5 else 1\n",
    "                else:\n",
    "                    return 1\n",
    "            else:\n",
    "                # Non-H 類別区分\n",
    "                return 0 if 5 <= row[\"Burden Ratio\"] <= 6 else 1\n",
    "\n",
    "        elif \"166005CA0A\" in row[\"Customer Parts No.\"]:\n",
    "            return 0 if 5 <= row[\"Burden Ratio\"] <= 6 else 1\n",
    "\n",
    "        elif (\n",
    "            \"166006MR0B\" in row[\"Customer Parts No.\"]\n",
    "            or \"166006MR0C\" in row[\"Customer Parts No.\"]\n",
    "        ):\n",
    "            return 0 if 5 <= row[\"Burden Ratio\"] <= 6 else 1\n",
    "\n",
    "        else:\n",
    "            # Assign 0 but flag irregular case in \"Irregular case BR\"\n",
    "            # (Mutation is kept for behavior compatibility, even if apply() won't persist it.)\n",
    "            row[\"Irregular case BR\"] = 1\n",
    "            return 0\n",
    "\n",
    "    if row[\"EZKL Name\"] == \"LUFT\":\n",
    "        return 0\n",
    "\n",
    "    if pd.isna(row[\"EZKL Name\"]):\n",
    "        return 0\n",
    "\n",
    "    # Default logic for non-HDEV5 / non-LUFT\n",
    "    new_br_date = pd.to_datetime(row[\"New BR Date\"], errors=\"coerce\")\n",
    "    sap_date = pd.to_datetime(row[\"SAP Date\"], errors=\"coerce\")\n",
    "\n",
    "    if pd.isna(new_br_date):\n",
    "        return 0 if row[\"Burden Ratio\"] == row[\"Standard Burden Ratio\"] else 1\n",
    "\n",
    "    if sap_date < new_br_date:\n",
    "        return 0 if row[\"Burden Ratio\"] == row[\"Standard Burden Ratio\"] else 1\n",
    "\n",
    "    return 0 if row[\"Burden Ratio\"] == row[\"Current Burden Ratio\"] else 1\n",
    "\n",
    "\n",
    "def generate_claim(row: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Claim decision (main logic).\n",
    "\n",
    "    Returns 1 (claim) when any critical flag is raised and Right_Month / High Denied Paid Ratio are not blocking.\n",
    "    \"\"\"\n",
    "    # Automatically return 0 if Right_Month is 1\n",
    "    if row[\"Right_Month\"] == 1:\n",
    "        return 0\n",
    "\n",
    "    # Automatically return 0 if High Denied Paid Ratio is 1\n",
    "    if row[\"High Denied Paid Ratio\"] == 1:\n",
    "        return 0\n",
    "\n",
    "    # Check the other conditions only if the above are false\n",
    "    if (\n",
    "        row[\"TCA Outlier EZKL\"] == 1\n",
    "        or row[\"BR Contract\"] == 1\n",
    "        or row[\"Outside_warranty_period\"] == 1\n",
    "        or row[\"HDEV6_countermeasure\"] == 1\n",
    "        or row[\"HDEV6_over_120000\"] == 1\n",
    "    ):\n",
    "        return 1\n",
    "\n",
    "    # Return 0 if none of the conditions are met\n",
    "    return 0\n",
    "\n",
    "\n",
    "def generate_claim_DPR(row: pd.Series) -> int:\n",
    "    \"\"\"\n",
    "    Claim decision variation for DPR logic.\n",
    "\n",
    "    Same as generate_claim, but does NOT consider 'High Denied Paid Ratio'.\n",
    "    \"\"\"\n",
    "    # Automatically return 0 if Right_Month is 1\n",
    "    if row[\"Right_Month\"] == 1:\n",
    "        return 0\n",
    "\n",
    "    # Check the other conditions only if the above are false\n",
    "    if (\n",
    "        row[\"TCA Outlier EZKL\"] == 1\n",
    "        or row[\"BR Contract\"] == 1\n",
    "        or row[\"Outside_warranty_period\"] == 1\n",
    "        or row[\"HDEV6_countermeasure\"] == 1\n",
    "        or row[\"HDEV6_over_120000\"] == 1\n",
    "    ):\n",
    "        return 1\n",
    "\n",
    "    # Return 0 if none of the conditions are met\n",
    "    return 0\n",
    "\n",
    "\n",
    "def assign_group(part_number: str) -> str:\n",
    "    \"\"\"\n",
    "    Assign a group based on the prefix of the part number.\n",
    "    Uses PART_GROUP_PATTERNS, checking longest prefixes first.\n",
    "    \"\"\"\n",
    "    if not isinstance(part_number, str):\n",
    "        part_number = str(part_number)\n",
    "\n",
    "    for prefix in sorted(PART_GROUP_PATTERNS, key=len, reverse=True):\n",
    "        if part_number.startswith(prefix):\n",
    "            return PART_GROUP_PATTERNS[prefix]\n",
    "    return \"Unknown\"\n",
    "\n",
    "\n",
    "def normalize_expected(value):\n",
    "    \"\"\"\n",
    "    Normalize 'Expected group' free-text into a standard label.\n",
    "    - Lowercases / strips\n",
    "    - Cuts off after ';', ',' or ':' if present\n",
    "    - Maps through EXPECTED_GROUP_NORMALIZATION\n",
    "    \"\"\"\n",
    "    if not value:\n",
    "        return \"unassigned\"\n",
    "\n",
    "    val = str(value).strip().lower()\n",
    "\n",
    "    # Remove known suffixes after delimiters (e.g., ';', ',', ':')\n",
    "    for delimiter in [\";\", \",\", \":\"]:\n",
    "        if delimiter in val:\n",
    "            val = val.split(delimiter)[0].strip()\n",
    "            break\n",
    "\n",
    "    # Normalize using dictionary\n",
    "    return EXPECTED_GROUP_NORMALIZATION.get(val, val)\n",
    "\n",
    "\n",
    "def is_similar(a: str, b: str, threshold: int = 90) -> bool:\n",
    "    \"\"\"\n",
    "    Fuzzy similarity between two strings using rapidfuzz.ratio.\n",
    "    Returns True if similarity >= threshold.\n",
    "    \"\"\"\n",
    "    return fuzz.ratio(a.lower(), b.lower()) >= threshold\n",
    "\n",
    "\n",
    "def refno_to_month_code(ref_no):\n",
    "    \"\"\"\n",
    "    Extract 3rd char of Reference No. and map to month code (Jan, Feb, ...).\n",
    "    Uses MONTH_LETTER_TO_CODE.\n",
    "    \"\"\"\n",
    "    if pd.isna(ref_no):\n",
    "        return None\n",
    "\n",
    "    s = str(ref_no).strip()\n",
    "    if len(s) < 3:\n",
    "        return None\n",
    "\n",
    "    letter = s[2].upper()\n",
    "    return MONTH_LETTER_TO_CODE.get(letter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 3. PATHS & FILE LOCATIONS\n",
    "# ============================================================\n",
    "\n",
    "# Convert claim date to compact yymm format (input: yyyy/mm/dd)\n",
    "date_obj = datetime.strptime(CLAIM_DATE, \"%Y/%m/%d\")\n",
    "DATE_YYMM = date_obj.strftime(\"%y%m\")     # e.g., 2025/10/01 → \"2510\"\n",
    "DATE_YYYYMM = date_obj.strftime(\"%Y%m\")   # sometimes needed\n",
    "\n",
    "\n",
    "# Base SharePoint directory\n",
    "ROOT_DIR = r\"\\\\bosch.com\\DfsRB\\DfsJP\\DIV\\PS\\z_Collabo\\0215_QMM_JP3_Share\\Claim_WBS\\4.Warranty_Info\\11.Nissan_異議\"\n",
    "\n",
    "\n",
    "# Path to unlabeled Nissan objection Excel file\n",
    "file_path = fr\"{ROOT_DIR}\\20{DATE_YYMM}\\nissan_{DATE_YYMM}_GB.xlsx\"\n",
    "\n",
    "# Path to save predicted labels / outputs\n",
    "result_file_path = fr\"{ROOT_DIR}\\20{DATE_YYMM}\"\n",
    "\n",
    "\n",
    "# Replacement dictionary for product names and EZKL corrections\n",
    "REPLACEMENTS = {\n",
    "    \"HDEV\": \"HDEV5\",             # Unspecified HDEV assumed to be HDEV5\n",
    "    \"EKP/T\": \"EKPT\",\n",
    "    \"EGT-PC\": \"EGT-PC(DM3.4)\",   # (or EGT-PC(MIXER) depending on rule; unchanged here)\n",
    "    \"EV(Do)\": \"EV\",\n",
    "}\n",
    "\n",
    "# ============================================================\n",
    "# 3.B POWER BI TEMPLATE / SCHEMA CONFIG\n",
    "# ============================================================\n",
    "\n",
    "# Template used only for column/schema alignment\n",
    "AI_TEMPLATE_PATH = fr\"{ROOT_DIR}\\AI_validated_claims_template.xlsx\"\n",
    "\n",
    "# Historical clean file (non-aggregated)\n",
    "AI_CLAIMS_CLEAN_PATH = fr\"{ROOT_DIR}\\AI_validated_claims_clean.xlsx\"\n",
    "\n",
    "# Aggregated file consumed by Power BI\n",
    "AI_CLAIMS_AGG_PATH = fr\"{ROOT_DIR}\\AI_validated_claims.xlsx\"\n",
    "\n",
    "# Mapping from old Power BI column names → new refactor column names\n",
    "# Extend this dict if you find more legacy Japanese columns later.\n",
    "COLUMN_MAPPING = {\n",
    "    \"判定.1\": \"claim\",   # old column used by the model → new \"claim\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111514 is marked as a date but the serial value 20180614 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111515 is marked as a date but the serial value 20180614 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111517 is marked as a date but the serial value 20190708 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111518 is marked as a date but the serial value 20190708 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111519 is marked as a date but the serial value 20190704 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111530 is marked as a date but the serial value 20190405 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111531 is marked as a date but the serial value 20190703 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111582 is marked as a date but the serial value 20190820 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111583 is marked as a date but the serial value 20190820 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111584 is marked as a date but the serial value 20190711 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111585 is marked as a date but the serial value 20190319 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111586 is marked as a date but the serial value 20190319 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111587 is marked as a date but the serial value 20190430 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111588 is marked as a date but the serial value 20190430 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111589 is marked as a date but the serial value 20191030 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111590 is marked as a date but the serial value 20190624 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111591 is marked as a date but the serial value 20190823 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111592 is marked as a date but the serial value 20190823 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111616 is marked as a date but the serial value 20190829 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111617 is marked as a date but the serial value 20190829 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111618 is marked as a date but the serial value 20181003 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "c:\\Users\\ALG1YH\\.conda\\envs\\bosch-py310\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:223: UserWarning: Cell BI111619 is marked as a date but the serial value 20181003 is outside the limits for dates. The cell will be treated as an error.\n",
      "  warn(msg)\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\2948718818.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan[\"SAP Date\"] = pd.to_datetime(df_ps_nissan[\"SAP Date\"], errors=\"coerce\")\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\2948718818.py:149: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_burden_nissan.drop(\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4. DATA LOADING\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.1 PS DATA (GLOBAL, SLOW TO LOAD)\n",
    "# ------------------------------------------------------------\n",
    "# Note:\n",
    "# PS data takes a long time to load (~7 min). When iterating on\n",
    "# logic below, you can comment this block out *after* it is in\n",
    "# memory, as long as you don't restart the kernel.\n",
    "\n",
    "df_ps = pd.read_excel(\n",
    "    r\"\\\\bosch.com\\dfsrb\\DfsJP\\DIV\\PS\\QMC\\All\\06.QMM_QMD\\60.Data_Base\\2.Warranty_data\\PS_Database.xlsm\",\n",
    "    sheet_name=\"PS_Data\",\n",
    "    header=1,\n",
    ")\n",
    "\n",
    "# Translation sheet for PS columns\n",
    "df_ps_translation = pd.read_excel(\n",
    "    r\"\\\\bosch.com\\dfsrb\\DfsJP\\DIV\\PS\\QMC\\All\\06.QMM_QMD\\60.Data_Base\\2.Warranty_data\\PS_Database.xlsm\",\n",
    "    sheet_name=\"Translation\",\n",
    "    header=0,\n",
    ")\n",
    "df_ps = translate(df_ps, df_ps_translation, column1=\"PS_Data Columns\", column2=\"Translated Version\")\n",
    "\n",
    "# --- Master EZKL lookup from full PS database (no Nissan filter) ---\n",
    "\n",
    "# Normalize Bosch part numbers\n",
    "df_ps[\"Bosch Parts No. norm\"] = df_ps[\"Bosch Parts No.\"].apply(normalize_bosch_part_no)\n",
    "df_ps[\"Bosch Prefix 10\"] = df_ps[\"Bosch Parts No. norm\"].str[:10]\n",
    "\n",
    "# Build mapping: prefix -> most common EZKL Name\n",
    "ezkl_lookup = (\n",
    "    df_ps\n",
    "    .dropna(subset=[\"Bosch Prefix 10\", \"EZKL Name\"])\n",
    "    .groupby(\"Bosch Prefix 10\")[\"EZKL Name\"]\n",
    "    .agg(lambda s: s.mode().iat[0] if not s.mode().empty else s.iloc[0])\n",
    "    .reset_index()\n",
    "    .rename(columns={\"EZKL Name\": \"EZKL_from_PS\"})\n",
    ")\n",
    "\n",
    "# Ensure SAP Date is datetime before any filtering\n",
    "df_ps[\"SAP Date\"] = pd.to_datetime(df_ps[\"SAP Date\"], errors=\"coerce\")\n",
    "\n",
    "# Filter for Nissan-related data\n",
    "df_ps_nissan = df_ps[df_ps[\"OEM Name\"] == \"日産\"]\n",
    "df_ps_nissan = df_ps_nissan[df_ps_nissan[\"Key No.\"] != \"M\"]\n",
    "\n",
    "cutoff = pd.Timestamp(\"2021-01-01\")\n",
    "df_ps_nissan = df_ps_nissan[df_ps_nissan[\"SAP Date\"] >= cutoff]\n",
    "\n",
    "df_ps_nissan[\"Objection ID\"] = df_ps_nissan[\"Reference No.\"].str[:8]\n",
    "df_ps_nissan[\"Bosch Parts No. Prefix\"] = df_ps_nissan[\"Bosch Parts No.\"].str[:10]\n",
    "\n",
    "# Exclude irrelevant cases\n",
    "df_ps_nissan = df_ps_nissan[\n",
    "    ~df_ps_nissan[\"Bosch Parts Name\"].isin([\"CP1H recall\", \"新負担割合による遡及精算分\", \"ECM　キャンペーン費用\"])\n",
    "]\n",
    "df_ps_nissan = df_ps_nissan[~df_ps_nissan[\"EZKL Name\"].str.contains(r\"\\(S\\)\")]\n",
    "\n",
    "# Replace EZKL Names based on replacement dictionary (from config)\n",
    "df_ps_nissan[\"EZKL Name\"] = df_ps_nissan[\"EZKL Name\"].replace(REPLACEMENTS)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_ps_nissan = df_ps_nissan.drop(\n",
    "    columns=[\"Product Code(DS)\", \"Product Code\", \"Sequence No.\", \"c3\", \"Division\"]\n",
    ")\n",
    "\n",
    "# Drop duplicate Reference No., keeping most recent SAP Date\n",
    "df_sorted = df_ps_nissan.sort_values(by=[\"Reference No.\", \"SAP Date\"], ascending=[True, False])\n",
    "df_ps_nissan = df_sorted.drop_duplicates(subset=\"Reference No.\", keep=\"first\")\n",
    "\n",
    "# Filter to exclude the current claim month from PS database\n",
    "df_ps_nissan[\"SAP Date\"] = pd.to_datetime(df_ps_nissan[\"SAP Date\"], errors=\"coerce\")\n",
    "df_ps_nissan = df_ps_nissan.loc[df_ps_nissan[\"SAP Date\"] < claim_date_ts]\n",
    "\n",
    "# Convert installation date to datetime\n",
    "df_ps_nissan[\"Parts Warranty Installation Date\"] = df_ps_nissan[\n",
    "    \"Parts Warranty Installation Date\"\n",
    "].apply(convert_to_date)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.2 UNTRAINED (NEW) NISSAN DATA\n",
    "# ------------------------------------------------------------\n",
    "df_new = pd.read_excel(file_path, sheet_name=SHEET_PS)\n",
    "\n",
    "# Translation sheet for new Nissan objection file\n",
    "df_new_translation = pd.read_excel(\n",
    "    r\"\\\\bosch.com\\DfsRB\\DfsJP\\DIV\\PS\\z_Collabo\\0215_QMM_JP3_Share\\Claim_WBS\\4.Warranty_Info\\11.Nissan_異議\\Nissan_異議申請リスト_translated_forAI.xlsx\"\n",
    ")\n",
    "df_new = translate(df_new, df_new_translation, column1=\"Nissan Columns\", column2=\"Translated Version\")\n",
    "\n",
    "# Filter relevant divisions\n",
    "# df_new = df_new.loc[df_new[\"Parts Distinction\"] == 1]\n",
    "df_new = df_new.loc[df_new[\"Division\"].isin([\"PS(GS)\", \"PS(DS)\", \"P\"])]\n",
    "# \"P\" is actually an error resulting from the macros, this may be fixed in the near future\n",
    "\n",
    "# Extract key columns\n",
    "df_new[\"Objection ID\"] = df_new[\"Reference No.\"].str[:8]\n",
    "df_new[\"Bosch Parts No. Prefix\"] = df_new[\"Bosch Parts No.\"].str[:10]\n",
    "df_new[\"EZKL Name\"] = df_new[\"Bosch Parts No. Prefix\"].apply(\n",
    "    lambda x: get_most_common_ezkl(df_ps_nissan, x)\n",
    ")\n",
    "\n",
    "# Normalize Bosch Parts Name to lowercase\n",
    "df_new[\"Bosch Parts Name\"] = df_new[\"Bosch Parts Name\"].fillna(\"\").str.lower()\n",
    "\n",
    "# Standardize SAP Date name/type\n",
    "df_new[\"SAP Date\"] = df_new[\"EDP Date\"]\n",
    "df_new[\"SAP Date\"] = pd.to_datetime(df_new[\"SAP Date\"], errors=\"coerce\")\n",
    "\n",
    "# Exclude irrelevant cases\n",
    "df_new = df_new[\n",
    "    ~df_new[\"Bosch Parts Name\"].isin([\"CP1H recall\", \"新負担割合による遡及精算分\", \"ECM　キャンペーン費用\"])\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.3 BURDEN RATIO CONTRACT DATA\n",
    "# ------------------------------------------------------------\n",
    "df_burden = pd.read_excel(\n",
    "    r\"\\\\BOSCH.COM\\DfsRB\\DfsJP\\DIV\\PS\\z_Collabo\\0173_PSQMC_123\\PSQMC_Share\\2_General\\Quality_data\\Q_Reporting\\01 GS-JP External defect cost\\2 Customer別 要求事項\\顧客別負担割合一覧表.xlsx\",\n",
    "    sheet_name=\"2021\",\n",
    "    header=4,\n",
    ")\n",
    "\n",
    "# Translate columns\n",
    "df_burden.rename(\n",
    "    columns={\n",
    "        \"製品名\\n（EZKL名称）\": \"EZKL Name\",\n",
    "        \"製品コード\\n(EZKL)\": \"EZKL (Product Class)\",\n",
    "        \"基準負担率\\nBosch\": \"Standard Burden Ratio\",\n",
    "        \"現状負担率\\nBosch\": \"Current Burden Ratio\",\n",
    "        \"適用開始日\": \"New BR Date\",\n",
    "        \"変更後負担率有効期限\": \"New BR Expiry Date\",\n",
    "        \"備考1\": \"Remarks 1\",\n",
    "        \"備考2\": \"Remarks 2\",\n",
    "        \"最終更新日/確認日\": \"Last Updated Date\",\n",
    "    },\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Nissan-only rows\n",
    "df_burden_nissan = df_burden.loc[df_burden[\"メーカー\"] == \"NISSAN\"]\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_burden_nissan.drop(\n",
    "    columns=[\"Unnamed: 13\", \"メーカー\", \"代表品番\", \"負担率決定合意書保存先リンク\"],\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "# Exclude irrelevant cases for BR logic\n",
    "df_burden_nissan = df_burden_nissan[\n",
    "    ~(\n",
    "        (df_burden_nissan[\"EZKL Name\"] == \"LS\")\n",
    "        & (df_burden_nissan[\"Current Burden Ratio\"] == 1.5)\n",
    "    )\n",
    "]\n",
    "df_burden_nissan = df_burden_nissan[\n",
    "    ~(\n",
    "        (df_burden_nissan[\"EZKL Name\"] == \"HDEV5\")\n",
    "        & ~(df_burden_nissan[\"Current Burden Ratio\"] == \"5.5\\n(一部50%)\")\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4.4 OBJECTION DATA (HISTORICAL)\n",
    "# ------------------------------------------------------------\n",
    "# Kept for reference and possible future ML usage.\n",
    "df_obj_nissan = pd.read_excel(\n",
    "    r\"\\\\BOSCH.COM\\DfsRB\\DfsJP\\DIV\\PS\\z_Collabo\\0215_QMM_JP3_Share\\Claim_WBS\\4.Warranty_Info\\異議申請状況確認リスト_PC.xlsx\",\n",
    "    sheet_name=\"Nissan\",\n",
    "    header=1,\n",
    ")\n",
    "\n",
    "df_obj_translation = pd.read_excel(\n",
    "    r\"\\\\BOSCH.COM\\DfsRB\\DfsJP\\DIV\\PS\\z_Collabo\\0215_QMM_JP3_Share\\Claim_WBS\\4.Warranty_Info\\異議申請状況確認リスト_PC.xlsx\",\n",
    "    sheet_name=\"Translation\",\n",
    "    header=0,\n",
    ")\n",
    "df_obj_nissan = translate(df_obj_nissan, df_obj_translation, column1=\"Nissan Columns\", column2=\"Translated Version\")\n",
    "\n",
    "df_obj_nissan.rename(\n",
    "    columns={\"Return Amount\": \"Saved Amount\", \"Return Amount1\": \"Saved Amount1\"},\n",
    "    inplace=True,\n",
    ")\n",
    "\n",
    "df_excluded_nissan = df_obj_nissan[df_obj_nissan[\"Status\"] == \"申請中\"]\n",
    "df_obj_nissan = df_obj_nissan[df_obj_nissan[\"Status\"].isin([\"却下\", \"受理\"])]\n",
    "\n",
    "df_obj_nissan[\"Objection ID\"] = df_obj_nissan[\"Reference No.\"].str[:8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 5. CONTROL UNIT NORMALIZATION + MERGES\n",
    "# ============================================================\n",
    "\n",
    "# Normalize Bosch Parts Name to lower case for matching\n",
    "name_col = df_ps_nissan[\"Bosch Parts Name\"].fillna(\"\").str.lower()\n",
    "\n",
    "# Ensure EZKL column exists (safety, even though it should already be present)\n",
    "if \"EZKL Name\" not in df_ps_nissan.columns:\n",
    "    df_ps_nissan[\"EZKL Name\"] = None\n",
    "\n",
    "# Assign EZKL \"Control Unit\" to any PS rows whose name contains \"control unit\"\n",
    "df_ps_nissan.loc[name_col.str.contains(\"control unit\"), \"EZKL Name\"] = \"Control Unit\"\n",
    "\n",
    "# Merge PS Nissan data with Burden Ratio table (no Control Unit row yet → preserves original behavior)\n",
    "df_ps_nissan = df_ps_nissan.merge(\n",
    "    df_burden_nissan[[\"EZKL Name\", \"Standard Burden Ratio\", \"Current Burden Ratio\", \"New BR Date\"]],\n",
    "    on=\"EZKL Name\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Add Control Unit row to burden table if not already present\n",
    "if \"Control Unit\" not in df_burden_nissan[\"EZKL Name\"].values:\n",
    "    control_unit_row = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"EZKL Name\": \"Control Unit\",\n",
    "                \"Standard Burden Ratio\": 0.5,\n",
    "                \"Current Burden Ratio\": 0.5,\n",
    "                \"New BR Date\": pd.to_datetime(\"2021-01-01\"),\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    df_burden_nissan = pd.concat([df_burden_nissan, control_unit_row], ignore_index=True)\n",
    "\n",
    "# Merge objection status into PS Nissan data\n",
    "df_ps_nissan = df_ps_nissan.merge(\n",
    "    df_obj_nissan[[\"Objection ID\", \"Total Claimed Amount\", \"Status\"]],\n",
    "    on=[\"Objection ID\", \"Total Claimed Amount\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Merge Burden Ratio into new (untrained) Nissan data\n",
    "df_new = df_new.merge(\n",
    "    df_burden_nissan[[\"EZKL Name\", \"Standard Burden Ratio\", \"Current Burden Ratio\", \"New BR Date\"]],\n",
    "    on=\"EZKL Name\",\n",
    "    how=\"left\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3889805991.py:64: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan.drop(columns=[\"Status_temp\"], inplace=True)\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3889805991.py:86: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '[  nan   nan 2008. 2008. 2024. 2018.]' has dtype incompatible with datetime64[ns], please explicitly cast to a compatible dtype first.\n",
      "  df_new.loc[df_new[\"Vehicle MFD\"].isna(), \"Vehicle MFD\"] = df_new[\"Vehicle Registration Date\"].dt.year\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3889805991.py:99: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_ps_nissan[\"Passed Month\"].fillna(mean_passed_month, inplace=True)\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3889805991.py:99: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan[\"Passed Month\"].fillna(mean_passed_month, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 6. EXTRA DATA CURATION\n",
    "#    - Duplicate resolution\n",
    "#    - Missing values treatment\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6.1 Merging Duplicates Issue\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Translate Status values (JP → EN)\n",
    "df_ps_nissan[\"Status\"] = df_ps_nissan[\"Status\"].map({\"却下\": \"Rejected\", \"受理\": \"Accepted\"})\n",
    "\n",
    "# Count occurrences of each Objection ID\n",
    "obj_id_counts = df_ps_nissan[\"Objection ID\"].value_counts()\n",
    "\n",
    "# Temporary status to distinguish NaN rows\n",
    "df_ps_nissan[\"Status_temp\"] = df_ps_nissan.apply(\n",
    "    lambda row: f\"NaN_{row.name}\" if pd.isna(row[\"Status\"]) else row[\"Status\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "# Objection IDs that appear exactly twice\n",
    "obj_ids_twice = obj_id_counts[obj_id_counts == 2].index\n",
    "obj_no_2 = df_ps_nissan[df_ps_nissan[\"Objection ID\"].isin(obj_ids_twice)]\n",
    "\n",
    "# Among those, IDs with more than one distinct Status_temp (i.e., conflicting statuses)\n",
    "status_counts = obj_no_2.groupby(\"Objection ID\")[\"Status_temp\"].nunique()\n",
    "conflict_ids = status_counts[status_counts > 1].index\n",
    "\n",
    "# For conflicting IDs, get the earliest SAP Date row\n",
    "OBJ_SAP = df_ps_nissan[df_ps_nissan[\"Objection ID\"].isin(conflict_ids)].sort_values(\n",
    "    by=[\"Objection ID\", \"SAP Date\"],\n",
    "    ascending=True,\n",
    ")\n",
    "\n",
    "OBJ_SAP_sorted = OBJ_SAP.sort_values(by=[\"Objection ID\", \"SAP Date\"], ascending=True)\n",
    "OBJ_SAP_order = OBJ_SAP_sorted.drop_duplicates(subset=[\"Objection ID\"], keep=\"first\")\n",
    "\n",
    "# Attach earliest SAP Date per conflicting Objection ID\n",
    "earliest = OBJ_SAP_order[[\"Objection ID\", \"SAP Date\"]].rename(\n",
    "    columns={\"SAP Date\": \"Earliest SAP Date\"}\n",
    ")\n",
    "df_ps_nissan = df_ps_nissan.merge(earliest, on=\"Objection ID\", how=\"left\")\n",
    "\n",
    "# Drop later SAP Date rows for those conflicting IDs\n",
    "mask_drop = (\n",
    "    df_ps_nissan[\"Earliest SAP Date\"].notna()\n",
    "    & (df_ps_nissan[\"SAP Date\"] > df_ps_nissan[\"Earliest SAP Date\"])\n",
    ")\n",
    "df_ps_nissan = df_ps_nissan[~mask_drop].drop(columns=[\"Earliest SAP Date\"])\n",
    "\n",
    "# Final dedupe: keep last record per (Objection ID, Total Claimed Amount)\n",
    "df_nissan_sorted = df_ps_nissan.sort_values(\n",
    "    by=[\"Objection ID\", \"Total Claimed Amount\", \"SAP Date\"],\n",
    "    ascending=True,\n",
    ")\n",
    "df_ps_nissan = df_nissan_sorted.drop_duplicates(\n",
    "    subset=[\"Objection ID\", \"Total Claimed Amount\"],\n",
    "    keep=\"last\",\n",
    ")\n",
    "\n",
    "# Clean up temp column\n",
    "df_ps_nissan.drop(columns=[\"Status_temp\"], inplace=True)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6.2 Treating Missing Values\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Mean registration-to-failure time (for both PS and new data fallback)\n",
    "mean_reg_fal_time = (\n",
    "    df_ps_nissan[\"Vehicle Failure Date\"].mean()\n",
    "    - df_ps_nissan[\"Vehicle Registration Date\"].mean()\n",
    ")\n",
    "\n",
    "# Fill missing Vehicle MFD in PS data\n",
    "for index, row in df_ps_nissan[df_ps_nissan[\"Vehicle MFD\"].isna()].iterrows():\n",
    "    if pd.notna(row[\"Vehicle Registration Date\"]):\n",
    "        df_ps_nissan.at[index, \"Vehicle MFD\"] = row[\"Vehicle Registration Date\"]\n",
    "    else:\n",
    "        df_ps_nissan.at[index, \"Vehicle MFD\"] = row[\"Vehicle Failure Date\"] - mean_reg_fal_time\n",
    "\n",
    "# Fill missing Vehicle MFD in new data\n",
    "# 1st rule: use Vehicle Registration Date year when available\n",
    "df_new.loc[df_new[\"Vehicle MFD\"].isna(), \"Vehicle MFD\"] = df_new[\"Vehicle Registration Date\"].dt.year\n",
    "\n",
    "# 2nd rule: for remaining NaN, approximate with Failure Date minus mean lag\n",
    "df_new.loc[df_new[\"Vehicle MFD\"].isna(), \"Vehicle MFD\"] = (\n",
    "    df_new.loc[df_new[\"Vehicle MFD\"].isna(), \"Vehicle Failure Date\"] - mean_reg_fal_time\n",
    ")\n",
    "\n",
    "# Normalize Vehicle MFD in df_new to proper datetime\n",
    "df_new[\"Vehicle MFD\"] = df_new[\"Vehicle MFD\"].apply(clean_vehicle_mfd)\n",
    "df_new[\"Vehicle MFD\"] = pd.to_datetime(df_new[\"Vehicle MFD\"])\n",
    "\n",
    "# Fill missing Passed Month in PS data\n",
    "mean_passed_month = df_ps_nissan[\"Passed Month\"].mean()\n",
    "df_ps_nissan[\"Passed Month\"].fillna(mean_passed_month, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3232548.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan[\"SAP Date\"] = pd.to_datetime(df_ps_nissan[\"SAP Date\"], format=\"%Y-%m-%d\")\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3232548.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan[\"New BR Date\"] = pd.to_datetime(df_ps_nissan[\"New BR Date\"])\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3232548.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan[\"Parts Warranty Installation Date\"] = pd.to_datetime(\n",
      "C:\\Users\\ALG1YH\\AppData\\Local\\Temp\\ipykernel_28404\\3232548.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ps_nissan.loc[:, \"Claim Status\"] = df_ps_nissan[\"Status\"].replace(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining EZKL NaN after fallback: 0\n",
      "std_summary columns: ['EZKL Name', 'Mean_TCA', 'Std_TCA', 'Mean_Plus_Std']\n",
      "Has Mean_Plus_Std in df_new?: True\n",
      "   Reference No. Irr. Month\n",
      "0       D5J00001        Nov\n",
      "1       D5J00002        Nov\n",
      "2       D5J00005        Nov\n",
      "3       D5J00025        Nov\n",
      "4       D5J00025        Nov\n",
      "5       D5J00025        Nov\n",
      "6       D5J00025        Nov\n",
      "7       D5J00026        Nov\n",
      "8       D5J00027        Nov\n",
      "9       D5J00028        Nov\n",
      "10      D5J00029        Nov\n",
      "11      D5J00029        Nov\n",
      "12      D5J00029        Nov\n",
      "13      D5J00029        Nov\n",
      "14      D5J00029        Nov\n",
      "15      D5J00029        Nov\n",
      "16      D5J00029        Nov\n",
      "17      D5J00029        Nov\n",
      "18      D5J00029        Nov\n",
      "19      D5J00029        Nov\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 7. FEATURE ENGINEERING & SELECTION\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.1 Fixing Data Types\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_ps_nissan[\"SAP Date\"] = pd.to_datetime(df_ps_nissan[\"SAP Date\"], format=\"%Y-%m-%d\")\n",
    "df_ps_nissan[\"New BR Date\"] = pd.to_datetime(df_ps_nissan[\"New BR Date\"])\n",
    "df_ps_nissan[\"Parts Warranty Installation Date\"] = pd.to_datetime(\n",
    "    df_ps_nissan[\"Parts Warranty Installation Date\"]\n",
    ")\n",
    "\n",
    "df_burden_nissan[\"New BR Date\"] = pd.to_datetime(df_burden_nissan[\"New BR Date\"])\n",
    "\n",
    "df_new[\"Vehicle MFD\"] = pd.to_datetime(df_new[\"Vehicle MFD\"])\n",
    "df_new[\"SAP Date\"] = pd.to_datetime(df_new[\"SAP Date\"])\n",
    "df_new[\"New BR Date\"] = pd.to_datetime(df_new[\"New BR Date\"])\n",
    "df_new[\"Download Date\"] = pd.to_datetime(df_new[\"Download Date\"])\n",
    "df_new[\"Parts Warranty Installation Date\"] = pd.to_datetime(\n",
    "    df_new[\"Parts Warranty Installation Date\"]\n",
    ")\n",
    "\n",
    "# (CLAIM_DATE already used to define claim_date_ts earlier; no need to redefine)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.2 Control-unit EZKL patch (blank ECU → ECU-PC/GS)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "mask_blank_control_unit = (\n",
    "    df_new[\"EZKL Name\"].isna()\n",
    "    & df_new[\"Bosch Parts Name\"].str.lower().str.contains(\"control unit\", na=False)\n",
    ")\n",
    "df_new.loc[mask_blank_control_unit, \"EZKL Name\"] = \"ECU-PC/GS\"\n",
    "df_new.loc[mask_blank_control_unit, \"Original_EZKL_Name\"] = \"ECU-PC/GS\"\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.3 Global stats, Claim Status, and DPR (Denied Paid Ratio)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Overall TCA stats\n",
    "std_amount = df_ps_nissan[\"Total Claimed Amount\"].std()\n",
    "mean_amount = df_ps_nissan[\"Total Claimed Amount\"].mean()\n",
    "sigma_1_5_above = mean_amount + std_amount * 1.5\n",
    "sigma_1_above = mean_amount + std_amount\n",
    "\n",
    "# Domestic / Overseas stats\n",
    "std_amount_dom = df_ps_nissan.loc[\n",
    "    df_ps_nissan[\"Domestic/Overseas\"] == \"1\", \"Total Claimed Amount\"\n",
    "].std()\n",
    "mean_amount_dom = df_ps_nissan.loc[\n",
    "    df_ps_nissan[\"Domestic/Overseas\"] == \"1\", \"Total Claimed Amount\"\n",
    "].mean()\n",
    "sigma_1_above_dom = mean_amount_dom + std_amount_dom\n",
    "\n",
    "std_amount_over = df_ps_nissan.loc[\n",
    "    df_ps_nissan[\"Domestic/Overseas\"] == \"2\", \"Total Claimed Amount\"\n",
    "].std()\n",
    "mean_amount_over = df_ps_nissan.loc[\n",
    "    df_ps_nissan[\"Domestic/Overseas\"] == \"2\", \"Total Claimed Amount\"\n",
    "].mean()\n",
    "sigma_1_above_over = mean_amount_over + std_amount_over\n",
    "\n",
    "# 12-month PS window (currently unused, kept for potential TS)\n",
    "temp_df = df_ps_nissan.loc[\n",
    "    (df_ps_nissan[\"SAP Date\"] >= claim_date_ts - pd.DateOffset(months=12))\n",
    "    & (df_ps_nissan[\"SAP Date\"] <= claim_date_ts)\n",
    "]\n",
    "\n",
    "# Monthly stats in new data (not used downstream, but kept)\n",
    "df_new[\"Year_SAP\"] = df_new[\"SAP Date\"].dt.year\n",
    "df_new[\"Month_SAP\"] = df_new[\"SAP Date\"].dt.month\n",
    "std_monthly_EZKL_new = df_new.groupby(\n",
    "    [\"EZKL Name\", \"Year_SAP\", \"Month_SAP\"]\n",
    ")[\"Total Claimed Amount\"].std()\n",
    "mean_monthly_EZKL_new = df_new.groupby(\n",
    "    [\"EZKL Name\", \"Year_SAP\", \"Month_SAP\"]\n",
    ")[\"Total Claimed Amount\"].mean()\n",
    "sigma_1_above_monthly_EZKL_new = mean_monthly_EZKL_new + std_monthly_EZKL_new\n",
    "\n",
    "# Claim Status mapping\n",
    "df_ps_nissan.loc[:, \"Claim Status\"] = df_ps_nissan[\"Status\"].replace(\n",
    "    {\"Accepted\": \"Denied Claim\", \"Rejected\": \"Denied Paid Claim\"}\n",
    ")\n",
    "df_ps_nissan.loc[:, \"Claim Status\"] = df_ps_nissan[\"Claim Status\"].fillna(\"Paid Claim\")\n",
    "\n",
    "denied_paid_counts = (\n",
    "    df_ps_nissan.loc[\n",
    "        df_ps_nissan[\"Claim Status\"] == \"Denied Paid Claim\",\n",
    "        [\"EZKL Name\", \"Claim Status\"],\n",
    "    ]\n",
    "    .groupby(\"EZKL Name\")[\"Claim Status\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"Denied Paid Count\")\n",
    ")\n",
    "\n",
    "denied_counts = (\n",
    "    df_ps_nissan.loc[\n",
    "        df_ps_nissan[\"Claim Status\"] == \"Denied Claim\",\n",
    "        [\"EZKL Name\", \"Claim Status\"],\n",
    "    ]\n",
    "    .groupby(\"EZKL Name\")[\"Claim Status\"]\n",
    "    .count()\n",
    "    .reset_index(name=\"Denied Count\")\n",
    ")\n",
    "\n",
    "ratio_df = pd.merge(denied_paid_counts, denied_counts, on=\"EZKL Name\", how=\"outer\").fillna(0)\n",
    "ratio_df[\"Denied Paid Ratio\"] = np.where(\n",
    "    (ratio_df[\"Denied Count\"] == 0) & (ratio_df[\"Denied Paid Count\"] == 0),\n",
    "    0,\n",
    "    ratio_df[\"Denied Paid Count\"]\n",
    "    / (ratio_df[\"Denied Count\"] + ratio_df[\"Denied Paid Count\"]),\n",
    ")\n",
    "\n",
    "# Month-letter for current claim date\n",
    "current_letter = get_letter_from_claim_date(claim_date_ts)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.4 Special handling for new HDEV6 part (Customer P/N 166006RC1C)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_new[\"Standard Burden Ratio\"] = np.where(\n",
    "    (df_new[\"Customer Parts No.\"] == \"166006RC1C\") & (pd.isna(df_new[\"EZKL Name\"])),\n",
    "    df_new.loc[df_new[\"EZKL Name\"] == \"HDEV6\", \"Standard Burden Ratio\"].iloc[:1],\n",
    "    df_new[\"Standard Burden Ratio\"],\n",
    ")\n",
    "\n",
    "df_new[\"Current Burden Ratio\"] = np.where(\n",
    "    (df_new[\"Customer Parts No.\"] == \"166006RC1C\") & (pd.isna(df_new[\"EZKL Name\"])),\n",
    "    df_new.loc[df_new[\"EZKL Name\"] == \"HDEV6\", \"Current Burden Ratio\"].iloc[:1],\n",
    "    df_new[\"Current Burden Ratio\"],\n",
    ")\n",
    "\n",
    "df_new[\"New BR Date\"] = np.where(\n",
    "    (df_new[\"Customer Parts No.\"] == \"166006RC1C\") & (pd.isna(df_new[\"EZKL Name\"])),\n",
    "    df_new.loc[df_new[\"EZKL Name\"] == \"HDEV6\", \"New BR Date\"].iloc[:1],\n",
    "    df_new[\"New BR Date\"],\n",
    ")\n",
    "\n",
    "df_new[\"EZKL Name\"] = np.where(\n",
    "    (df_new[\"Customer Parts No.\"] == \"166006RC1C\") & (pd.isna(df_new[\"EZKL Name\"])),\n",
    "    \"HDEV6\",\n",
    "    df_new[\"EZKL Name\"],\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.5 FALLBACK: Fill remaining EZKL from full PS database\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# 1) Normalize Bosch P/N in df_new\n",
    "df_new[\"Bosch Parts No. norm\"] = df_new[\"Bosch Parts No.\"].apply(normalize_nissan_bosch_pn)\n",
    "df_new[\"Bosch Prefix 10\"] = df_new[\"Bosch Parts No. norm\"].str[:10]\n",
    "\n",
    "# ezkl_lookup already built in PS loading section; reuse it here.\n",
    "\n",
    "# 2) Fallback merge\n",
    "df_new = df_new.merge(ezkl_lookup, how=\"left\", on=\"Bosch Prefix 10\")\n",
    "\n",
    "# 3) Only fill where EZKL is still NaN\n",
    "df_new[\"EZKL Name\"] = df_new[\"EZKL Name\"].fillna(df_new[\"EZKL_from_PS\"])\n",
    "\n",
    "# 4) Cleanup helper column\n",
    "df_new.drop(columns=[\"EZKL_from_PS\"], inplace=True)\n",
    "\n",
    "print(\"Remaining EZKL NaN after fallback:\", df_new[\"EZKL Name\"].isna().sum())\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.6 Outlier flags and date-based features\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Outlier flags on TCA\n",
    "df_new[\"TCA Outlier15\"] = np.where(df_new[\"Total Claimed Amount\"] > sigma_1_5_above, 1, 0)\n",
    "df_new[\"TCA Outlier1\"] = np.where(df_new[\"Total Claimed Amount\"] > sigma_1_above, 1, 0)\n",
    "\n",
    "df_new[\"TCA Outlier_dom\"] = np.where(\n",
    "    (df_new[\"Domestic/Overseas\"] == \"2\")\n",
    "    & (df_new[\"Total Claimed Amount\"] > sigma_1_above_dom),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "df_new[\"TCA Outlier_over\"] = np.where(\n",
    "    (df_new[\"Domestic/Overseas\"] == \"2\")\n",
    "    & (df_new[\"Total Claimed Amount\"] > sigma_1_above_over),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "# Time deltas and OEM month decoding\n",
    "df_new[\"Days MFD SAP\"] = (df_new[\"SAP Date\"] - df_new[\"Vehicle MFD\"]).dt.days\n",
    "df_new[\"Days MFD Failure\"] = (df_new[\"Vehicle Failure Date\"] - df_new[\"Vehicle MFD\"]).dt.days\n",
    "df_new[\"MFD Year\"] = df_new[\"Vehicle MFD\"].dt.year\n",
    "df_new[\"OEM Date Month\"] = df_new[\"Objection ID\"].apply(get_OEM_date_month)\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.7 Burden Ratio contract check (BR Contract)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def safe_check_burden_ratio(row):\n",
    "    try:\n",
    "        return check_burden_ratio(row)\n",
    "    except TypeError:\n",
    "        return 0\n",
    "\n",
    "\n",
    "df_new[\"Irregular case BR\"] = 0\n",
    "df_new[\"BR Contract\"] = df_new.apply(safe_check_burden_ratio, axis=1)\n",
    "\n",
    "# Preserve EZKL at this stage for later hybrid flags\n",
    "df_new[\"Original_EZKL_Name\"] = df_new[\"EZKL Name\"]\n",
    "\n",
    "# Hybrid EZKL label\n",
    "df_new[\"EZKL_H\"] = df_new.apply(\n",
    "    lambda row: f\"{row['Original_EZKL_Name']} (H)\"\n",
    "    if isinstance(row[\"類別区分\"], str) and re.match(r\"^H\", row[\"類別区分\"])\n",
    "    else row[\"Original_EZKL_Name\"],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.8 EZKL statistics for TCA Outlier EZKL\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Cleanup any old stats columns if notebook re-run\n",
    "stats_cols_to_drop = [\n",
    "    \"Mean_TCA\",\n",
    "    \"Std_TCA\",\n",
    "    \"Mean_Plus_Std\",\n",
    "    \"Mean_TCA_x\",\n",
    "    \"Std_TCA_x\",\n",
    "    \"Mean_Plus_Std_x\",\n",
    "    \"Mean_TCA_y\",\n",
    "    \"Std_TCA_y\",\n",
    "    \"Mean_Plus_Std_y\",\n",
    "]\n",
    "df_new = df_new.drop(\n",
    "    columns=[c for c in stats_cols_to_drop if c in df_new.columns],\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "\n",
    "# Mean/std per EZKL\n",
    "std_summary = (\n",
    "    df_new.groupby(\"EZKL Name\")[\"Total Claimed Amount\"]\n",
    "    .agg(Mean_TCA=\"mean\", Std_TCA=\"std\")\n",
    "    .reset_index()\n",
    ")\n",
    "std_summary[\"Mean_Plus_Std\"] = std_summary[\"Mean_TCA\"] + std_summary[\"Std_TCA\"]\n",
    "\n",
    "print(\"std_summary columns:\", std_summary.columns.tolist())\n",
    "\n",
    "# Merge stats into df_new\n",
    "df_new = df_new.merge(std_summary, on=\"EZKL Name\", how=\"left\")\n",
    "print(\"Has Mean_Plus_Std in df_new?:\", \"Mean_Plus_Std\" in df_new.columns)\n",
    "\n",
    "df_new[\"TCA Outlier EZKL\"] = np.where(\n",
    "    df_new[\"Total Claimed Amount\"] > df_new[\"Mean_Plus_Std\"], 1, 0\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.9 HDEV6-specific flags and main-part exclusion\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "HDEV6_MAIN_PART_EXCLUDED = [\"166007JA1A\"]\n",
    "mask_hdev6_main_excl = df_new[\"Customer Parts No.\"].isin(HDEV6_MAIN_PART_EXCLUDED)\n",
    "\n",
    "df_new[\"HDEV6_CM\"] = np.where(\n",
    "    (df_new[\"EZKL Name\"] == \"HDEV6\")\n",
    "    & (df_new[\"Vehicle MFD\"] >= pd.to_datetime(\"2023-04-01\")),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "df_new[\"HDEV6_countermeasure\"] = np.where(\n",
    "    (df_new[\"EZKL Name\"] == \"HDEV6\")\n",
    "    & (df_new[\"Vehicle MFD\"] >= pd.to_datetime(\"2023-04-01\"))\n",
    "    & (df_new[\"TCA Outlier EZKL\"] == 1),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "df_new[\"HDEV6_over_120000\"] = np.where(\n",
    "    (df_new[\"EZKL Name\"] == \"HDEV6\")\n",
    "    & (df_new[\"Total Claimed Amount\"] >= 120000)\n",
    "    & (df_new[\"Total Claimed Amount\"] <= 200000),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "# Apply main-part exclusion (HDEV6 flags disabled for these parts)\n",
    "df_new.loc[mask_hdev6_main_excl, [\"HDEV6_countermeasure\", \"HDEV6_over_120000\"]] = 0\n",
    "\n",
    "# BR Contract logic for excluded main parts (must be exactly 50%)\n",
    "df_new.loc[mask_hdev6_main_excl, \"BR Contract\"] = 0\n",
    "br_ok_mask = df_new[\"Burden Ratio\"] == 50\n",
    "df_new.loc[mask_hdev6_main_excl & (~br_ok_mask), \"BR Contract\"] = 1\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.10 High Denied Paid Ratio (EZKL-level)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "deny_cols_to_drop = [\n",
    "    \"Denied Paid Ratio\",\n",
    "    \"Denied Count\",\n",
    "    \"Denied Paid Count\",\n",
    "    \"Denied Paid Ratio_x\",\n",
    "    \"Denied Count_x\",\n",
    "    \"Denied Paid Count_x\",\n",
    "    \"Denied Paid Ratio_y\",\n",
    "    \"Denied Count_y\",\n",
    "    \"Denied Paid Count_y\",\n",
    "]\n",
    "df_new = df_new.drop(\n",
    "    columns=[c for c in deny_cols_to_drop if c in df_new.columns],\n",
    "    errors=\"ignore\",\n",
    ")\n",
    "\n",
    "df_new = df_new.merge(\n",
    "    ratio_df[[\"EZKL Name\", \"Denied Paid Ratio\", \"Denied Count\", \"Denied Paid Count\"]],\n",
    "    on=\"EZKL Name\",\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_new[\"Denied Paid Ratio\"] = df_new[\"Denied Paid Ratio\"].fillna(0)\n",
    "df_new[\"Num Objected\"] = df_new[\"Denied Count\"] + df_new[\"Denied Paid Count\"]\n",
    "\n",
    "df_new[\"High Denied Paid Ratio\"] = np.where(\n",
    "    df_new[\"Num Objected\"] >= 10,\n",
    "    np.where(df_new[\"Denied Paid Ratio\"] >= 0.90, 1, 0),\n",
    "    0,\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.11 Warranty period and month checks\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_new[\"期間\"] = pd.to_numeric(df_new[\"期間\"], errors=\"coerce\").fillna(100)\n",
    "\n",
    "df_new[\"period_m_difference\"] = (\n",
    "    (df_new[\"Vehicle Failure Date\"].dt.year - df_new[\"Parts Warranty Installation Date\"].dt.year) * 12\n",
    "    + (df_new[\"Vehicle Failure Date\"].dt.month - df_new[\"Parts Warranty Installation Date\"].dt.month)\n",
    ")\n",
    "\n",
    "df_new[\"Outside_warranty_period\"] = np.where(\n",
    "    pd.isna(df_new[\"Parts Warranty Installation Date\"]),\n",
    "    0,\n",
    "    np.where(df_new[\"period_m_difference\"] > df_new[\"期間\"], 1, 0),\n",
    ")\n",
    "\n",
    "df_new[\"Right_Month\"] = df_new[\"Reference No.\"].astype(str).apply(\n",
    "    lambda row: 0 if row[2] == current_letter else 1\n",
    ")\n",
    "\n",
    "df_new[\"Irr. Month\"] = df_new[\"Reference No.\"].apply(refno_to_month_code)\n",
    "print(df_new[[\"Reference No.\", \"Irr. Month\"]].head(20))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.12 Hybrid label for Power BI (duplicate, kept intentionally)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_new[\"Hybrid_specification_EZKL\"] = np.where(\n",
    "    (df_new[\"Original_EZKL_Name\"] == \"HDEV5\")\n",
    "    & (df_new[\"類別区分\"].str[:1] == \"H\"),\n",
    "    \"HDEV5 (H)\",\n",
    "    df_new[\"Original_EZKL_Name\"],\n",
    ")\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7.13 Irregular-case flag and EZKL group count\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_new[\"Irregular_case\"] = np.where(\n",
    "    (df_new[\"Irregular case BR\"] == 1) | (df_new[\"Right_Month\"] == 1),\n",
    "    1,\n",
    "    0,\n",
    ")\n",
    "\n",
    "if \"Group Count\" in df_new.columns:\n",
    "    df_new = df_new.drop(columns=[\"Group Count\"])\n",
    "\n",
    "parts_count = df_new[\"EZKL Name\"].value_counts().reset_index()\n",
    "parts_count.columns = [\"EZKL Name\", \"Group Count\"]\n",
    "\n",
    "df_new = df_new.join(parts_count.set_index(\"EZKL Name\"), on=\"EZKL Name\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Reference No. Irr. Month\n",
      "0       D5J00001        Nov\n",
      "1       D5J00002        Nov\n",
      "2       D5J00005        Nov\n",
      "3       D5J00025        Nov\n",
      "4       D5J00025        Nov\n",
      "5       D5J00025        Nov\n",
      "6       D5J00025        Nov\n",
      "7       D5J00026        Nov\n",
      "8       D5J00027        Nov\n",
      "9       D5J00028        Nov\n",
      "10      D5J00029        Nov\n",
      "11      D5J00029        Nov\n",
      "12      D5J00029        Nov\n",
      "13      D5J00029        Nov\n",
      "14      D5J00029        Nov\n",
      "15      D5J00029        Nov\n",
      "16      D5J00029        Nov\n",
      "17      D5J00029        Nov\n",
      "18      D5J00029        Nov\n",
      "19      D5J00029        Nov\n",
      "Refactor results saved to: \\\\bosch.com\\DfsRB\\DfsJP\\DIV\\PS\\QMC\\All\\01.QMC11\\05_General\\06_internship\\20240901_Julia_Antonioli\\AI_Projects\\warranty-judge\\01. Nissan\\AI_Results\\results_refactor_202511.xlsx\n",
      "Refactor columns: ['Vehicle Type', 'Chassis No.', 'Engine Type1', 'Phenomenon Code', 'Reference No.', 'Vehicle MFD', 'Passed Month', 'Total Actual Amount', 'Claimed Parts Cost', 'Claimed Labour Cost', 'Claimed Additional Cost', 'Total Claimed Amount', 'Burden Ratio', 'km / Mileage', 'Parts Distinction', 'Replaced Parts', ' Working Parts Code', '判定', '請求違い\\n申請書番号', '異議理由', 'Domestic/Overseas', 'Customer Parts No.', 'Bosch Parts Name', '車種型式1', '整理NO_10', '判定.1', '国', '補償備考', '期間', '距離', '判定_距離', '判定_期間', '判定_トーイング費用', 'パーツクレーム判定', '上限基準金額', '上限基準_判定', 'Division', 'Bosch Parts No.', 'Product Code', 'Engine Type', '車種型式11', 'Parts Warranty Installation Date', '整理NO_10.1', 'Dealer Code', 'GWAWARRANTYKEY', 'GWAIMPORTKEY', 'Download Date', 'Sequence No.', 'EDP Date', '事業部1', '国内・海外区分1', '事業部2', '部品区分1', '主原因コード1', '類別区分', '大中小区分', 'エミッション', 'Engine No.', 'Cause Code', '原因名', '現象コード1', '現象名', '用途区分', '識別コード', 'クレーム区分', '決定区分', 'P/T区分', 'P/W区分', 'E/W区分', '工場コード', '自社品番(上10桁)', '自社品名1', '品目階層（上5桁)', '販売店コード1', 'Claim No.', '整理NO1', '車両生産年月1', 'Vehicle Registration Date', 'Vehicle Failure Date', '経過月数1', 'Actual Parts Cost', 'Actual Labour Cost', 'Actual Additional Cost', '請求部品代1', '請求工賃1', '請求付帯費用1', '請求金額合計1', '請求負担率1', '部品代係数', '為替レート(\\\\/$)', 'パーツワランティ取付年月1', 'パーツワランティ取付距離', '走行距離1', '個数OR件数', 'COUNT', 'OEM処理年月', 'OEM部品名称', '契約担当', '製品コード1', 'フレーム区分', 'フレーム№', 'VIN-WMI', '車種大区分', '車両開発コード', 'テキスト項目', '国名', '年式', 'Objection ID', 'Bosch Parts No. Prefix', 'EZKL Name', 'SAP Date', 'Standard Burden Ratio', 'Current Burden Ratio', 'New BR Date', 'Original_EZKL_Name', 'Year_SAP', 'Month_SAP', 'Bosch Parts No. norm', 'Bosch Prefix 10', 'TCA Outlier15', 'TCA Outlier1', 'TCA Outlier_dom', 'TCA Outlier_over', 'Days MFD SAP', 'Days MFD Failure', 'MFD Year', 'OEM Date Month', 'Irregular case BR', 'BR Contract', 'EZKL_H', 'Mean_TCA', 'Std_TCA', 'Mean_Plus_Std', 'TCA Outlier EZKL', 'HDEV6_CM', 'HDEV6_countermeasure', 'HDEV6_over_120000', 'Denied Paid Ratio', 'Denied Count', 'Denied Paid Count', 'Num Objected', 'High Denied Paid Ratio', 'period_m_difference', 'Outside_warranty_period', 'Right_Month', 'Irr. Month', 'Hybrid_specification_EZKL', 'Irregular_case', 'Group Count', 'claim', 'claim_DPR', 'AI_DATE', 'Burden Ratio Decimal', 'Subpart']\n",
      "Refactor results saved to: \\\\bosch.com\\DfsRB\\DfsJP\\DIV\\PS\\QMC\\All\\01.QMC11\\05_General\\06_internship\\20240901_Julia_Antonioli\\AI_Projects\\warranty-judge\\01. Nissan\\AI_Results\\results_refactor_202511.xlsx\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 8. APPLY RULE-BASED MODEL & SAVE RESULTS\n",
    "# ============================================================\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8.1 Apply claim logic\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "df_new[\"claim\"] = df_new.apply(generate_claim, axis=1)\n",
    "df_new[\"claim_DPR\"] = df_new.apply(generate_claim_DPR, axis=1)\n",
    "\n",
    "# Claim date for Power BI filtering\n",
    "df_new[\"AI_DATE\"] = claim_date_ts  # from CONFIG section\n",
    "\n",
    "\n",
    "# Convert burden ratio into decimal (0–1)\n",
    "df_new[\"Burden Ratio Decimal\"] = df_new[\"Burden Ratio\"] / 100.0\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8.2 Subpart validation filter\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "def apply_subpart_filter(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Subpart consistency check:\n",
    "    - For Parts Distinction = 2 (subparts), compare Bosch Parts Name (normalized)\n",
    "      vs part-number-based group (assign_group).\n",
    "    - If mismatch → 'To object?', else 'OK'.\n",
    "    - Propagate 'To object?' to Distinction = 1 rows sharing the same Reference No.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Step 1: work on subparts only\n",
    "    df2 = df[df[\"Parts Distinction\"] == 2].copy()\n",
    "\n",
    "    status_list = []\n",
    "    for _, row in df2.iterrows():\n",
    "        part_number = str(row.get(\"Customer Parts No.\", \"\")).strip()\n",
    "        raw_expected = row.get(\"Bosch Parts Name\", \"\")\n",
    "        normalized_expected = normalize_expected(raw_expected)\n",
    "        computed_group = assign_group(part_number).lower()\n",
    "\n",
    "        similar = is_similar(normalized_expected, computed_group)\n",
    "\n",
    "        if similar:\n",
    "            status_list.append(\"OK\")\n",
    "        else:\n",
    "            status_list.append(\"To object?\")\n",
    "\n",
    "    # Step 2: assign Subpart for Distinction = 2 rows\n",
    "    df2[\"Subpart\"] = status_list\n",
    "\n",
    "    # Keep unique Subpart per Reference No. + Customer Parts No.\n",
    "    df2_unique = df2[[\"Reference No.\", \"Customer Parts No.\", \"Subpart\"]].drop_duplicates()\n",
    "\n",
    "    # Step 3: merge back into full df\n",
    "    df = df.drop(columns=[\"Subpart\"], errors=\"ignore\")\n",
    "    df = df.merge(\n",
    "        df2_unique,\n",
    "        on=[\"Reference No.\", \"Customer Parts No.\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "\n",
    "    # Step 4: propagate \"To object?\" to Distinction = 1 rows\n",
    "    refs_with_bad_parts = df.loc[\n",
    "        (df[\"Parts Distinction\"] == 2) & (df[\"Subpart\"] == \"To object?\"),\n",
    "        \"Reference No.\",\n",
    "    ].unique()\n",
    "\n",
    "    df.loc[\n",
    "        (df[\"Parts Distinction\"] == 1) & (df[\"Reference No.\"].isin(refs_with_bad_parts)),\n",
    "        \"Subpart\",\n",
    "    ] = \"To object?\"\n",
    "\n",
    "    # Step 5: remaining NaN → \"OK\"\n",
    "    df[\"Subpart\"] = df[\"Subpart\"].fillna(\"OK\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Apply subpart filter\n",
    "results = apply_subpart_filter(df_new)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8.3 Recompute Irr. Month on final results table (robust)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "results[\"Irr. Month\"] = results[\"Reference No.\"].apply(refno_to_month_code)\n",
    "\n",
    "# Optional sanity check\n",
    "print(results[[\"Reference No.\", \"Irr. Month\"]].head(20))\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 8.4 Save results (refactor output, non-destructive)\n",
    "# ------------------------------------------------------------\n",
    "\n",
    "# Ensure legacy 判定.1 column exists for Power BI compatibility\n",
    "if \"判定.1\" not in results.columns:\n",
    "    if \"claim\" in results.columns:\n",
    "        results[\"判定.1\"] = results[\"claim\"]\n",
    "    else:\n",
    "        # Fallback if claim doesn't exist (shouldn't happen)\n",
    "        results[\"判定.1\"] = 0\n",
    "\n",
    "REF_RESULTS_PATH = (\n",
    "    r\"\\\\bosch.com\\DfsRB\\DfsJP\\DIV\\PS\\QMC\\All\\01.QMC11\\05_General\\06_internship\"\n",
    "    r\"\\20240901_Julia_Antonioli\\AI_Projects\\warranty-judge\\01. Nissan\\AI_Results\"\n",
    "    fr\"\\results_refactor_20{DATE_YYMM}.xlsx\"\n",
    ")\n",
    "\n",
    "results.to_excel(REF_RESULTS_PATH, index=False)\n",
    "print(\"Refactor results saved to:\", REF_RESULTS_PATH)\n",
    "print(\"Refactor columns:\", list(results.columns))\n",
    "\n",
    "# ============================================================\n",
    "# TEMPLATE / POWER BI SCHEMA CONFIG (GLOBAL)\n",
    "# ============================================================\n",
    "\n",
    "# Base directory already defined earlier:\n",
    "# ROOT_DIR = r\"...\\11.Nissan_異議\"\n",
    "\n",
    "# Template used to force Power BI schema consistency\n",
    "AI_TEMPLATE_PATH = fr\"{ROOT_DIR}\\AI_validated_claims_template.xlsx\"\n",
    "\n",
    "# Historical clean file (non-aggregated)\n",
    "AI_CLAIMS_CLEAN_PATH = fr\"{ROOT_DIR}\\AI_validated_claims_clean.xlsx\"\n",
    "\n",
    "# Aggregated file consumed by Power BI\n",
    "AI_CLAIMS_AGG_PATH = fr\"{ROOT_DIR}\\AI_validated_claims.xlsx\"\n",
    "\n",
    "# Mapping from old Power BI column names → new refactor column names\n",
    "COLUMN_MAPPING = {\n",
    "    \"判定.1\": \"claim\",   # old PBI column \"判定.1\" should now read from \"claim\"\n",
    "    # add more mappings here if needed later\n",
    "}\n",
    "\n",
    "results = align_to_template(\n",
    "    results,\n",
    "    AI_TEMPLATE_PATH,\n",
    "    column_mapping=COLUMN_MAPPING,\n",
    ")\n",
    "\n",
    "results.to_excel(REF_RESULTS_PATH, index=False)\n",
    "print(\"Refactor results saved to:\", REF_RESULTS_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated aggregate file saved to: \\\\bosch.com\\DfsRB\\DfsJP\\DIV\\PS\\z_Collabo\\0215_QMM_JP3_Share\\Claim_WBS\\4.Warranty_Info\\11.Nissan_異議\\AI_validated_claims.xlsx\n",
      "AI_DATE\n",
      "2025-06-01    796\n",
      "2025-03-01    736\n",
      "2025-04-01    731\n",
      "2025-10-01    674\n",
      "2025-11-01    647\n",
      "2025-08-01    640\n",
      "2025-07-01    513\n",
      "2025-09-01    473\n",
      "2024-10-01    106\n",
      "2025-02-01     94\n",
      "2024-11-01     94\n",
      "2024-12-01     91\n",
      "2025-01-01     87\n",
      "2025-05-01     76\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 9. APPEND MONTHLY RESULTS TO POWER BI AGGREGATE FILE\n",
    "# ============================================================\n",
    "\n",
    "# Try to load existing aggregate file; if missing, start empty\n",
    "try:\n",
    "    all_claims = pd.read_excel(AI_CLAIMS_AGG_PATH)\n",
    "    # Ensure AI_DATE is datetime\n",
    "    if \"AI_DATE\" in all_claims.columns:\n",
    "        all_claims[\"AI_DATE\"] = pd.to_datetime(\n",
    "            all_claims[\"AI_DATE\"], format=\"%Y-%m-%d\", errors=\"coerce\"\n",
    "        )\n",
    "    else:\n",
    "        # If for some reason no AI_DATE column, create it\n",
    "        all_claims[\"AI_DATE\"] = pd.NaT\n",
    "\n",
    "except FileNotFoundError:\n",
    "    # First run: no historical file yet\n",
    "    all_claims = pd.DataFrame(columns=results.columns)\n",
    "    all_claims[\"AI_DATE\"] = pd.to_datetime(all_claims.get(\"AI_DATE\", pd.Series([], dtype=\"datetime64[ns]\")))\n",
    "\n",
    "# Drop any existing rows for this month's AI_DATE\n",
    "dates_to_replace = results[\"AI_DATE\"].unique()\n",
    "all_claims = all_claims[~all_claims[\"AI_DATE\"].isin(dates_to_replace)]\n",
    "\n",
    "# Append current results\n",
    "all_claims = pd.concat([all_claims, results], ignore_index=True)\n",
    "\n",
    "# Align schema to the template so Power BI never complains about missing columns\n",
    "all_claims = align_to_template(\n",
    "    all_claims,\n",
    "    AI_TEMPLATE_PATH,\n",
    "    column_mapping=COLUMN_MAPPING,\n",
    ")\n",
    "\n",
    "# Sort for Power BI readability\n",
    "all_claims = (\n",
    "    all_claims\n",
    "    .sort_values(by=[\"AI_DATE\", \"EZKL Name\", \"Total Claimed Amount\"], ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "# Save aggregate file for Power BI\n",
    "all_claims.to_excel(AI_CLAIMS_AGG_PATH, index=False)\n",
    "\n",
    "print(\"Updated aggregate file saved to:\", AI_CLAIMS_AGG_PATH)\n",
    "print(all_claims[\"AI_DATE\"].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
